{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data/train.csv', dtype={'shop_id': np.int32, 'item_id': np.int32, 'item_cnt_day':np.int32})\n",
    "\n",
    "# vocabularies\n",
    "shops = pd.read_csv('data/shops.csv')\n",
    "items = pd.read_csv('data/items.csv')\n",
    "item_cats = pd.read_csv('data/item_categories.csv')\n",
    "SHOPS_COUNT = len(shops)\n",
    "ITEMS_COUNT = len(items)\n",
    "CATS_COUNT = len(item_cats)\n",
    "\n",
    "import polyglot\n",
    "from polyglot.detect import Detector\n",
    "from polyglot.mapping import Embedding\n",
    "import string\n",
    "\n",
    "VOCAB_SIZE = 64\n",
    "embeddings_ru = Embedding.load(\"data/ru_embeddings_pkl.tar.bz2\")\n",
    "embeddings_en = Embedding.load(\"data/en_embeddings_pkl.tar.bz2\")\n",
    "punctuation_table = str.maketrans({key: None for key in string.punctuation+string.digits})\n",
    "\n",
    "def encoder(entries):\n",
    "    encoded = []\n",
    "    for i,entry in enumerate(entries.tolist()):\n",
    "        entry = entry.translate(punctuation_table)\n",
    "\n",
    "        temp = []\n",
    "        for word in entry.split(\" \"):\n",
    "            if word.replace(\" \", \"\") in embeddings_en:\n",
    "                temp.append(embeddings_en[word])\n",
    "            elif word.replace(\" \", \"\") in embeddings_ru:\n",
    "                temp.append(embeddings_ru[word]) \n",
    "            else:\n",
    "                temp.append(np.array([0]*64)) \n",
    "        temp = np.array(temp).mean(axis=0)\n",
    "        encoded.append(temp)\n",
    "    return encoded\n",
    "\n",
    "shop_vec = encoder(shops.shop_name)\n",
    "item_vec = encoder(items.item_name)\n",
    "cat_vec = encoder(item_cats.item_category_name)\n",
    "\n",
    "shops['shop_vec'] = shop_vec\n",
    "items['item_vec'] = item_vec\n",
    "item_cats['cat_vec'] = cat_vec\n",
    "\n",
    "def preprocessing(dt):\n",
    "    # add feature month to train data\n",
    "    dt['month'] = dt.date_block_num % 12\n",
    "    dt['item_category_id'] = dt.join(items, on='item_id', how='left', lsuffix='item_id').item_category_id\n",
    "    dt['item_vec'] = dt.join(items, on='item_id', how='left', rsuffix='ref').item_vec\n",
    "    dt['cat_vec'] = dt.join(item_cats, on='item_category_id', how='left', rsuffix='ref').cat_vec\n",
    "    dt['shop_vec'] = dt.join(shops, on='shop_id', how='left', rsuffix='ref').shop_vec\n",
    "    return dt\n",
    "\n",
    "X = pd.DataFrame(data.groupby(['date_block_num','shop_id', 'item_id'])['item_cnt_day'].sum()).reset_index()\n",
    "X['item_price'] = pd.DataFrame(\n",
    "    data.groupby(['date_block_num','shop_id', 'item_id'])['item_price'].mean()).reset_index().item_price\n",
    "X = preprocessing(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "month_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_emb (Embedding)           (None, 1, 2)         24          month_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "date_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_flat (Flatten)            (None, 2)            0           month_emb[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "category_input (InputLayer)     (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_input (InputLayer)         (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inputs_concat (Concatenate)     (None, 195)          0           date_input[0][0]                 \n",
      "                                                                 month_flat[0][0]                 \n",
      "                                                                 item_input[0][0]                 \n",
      "                                                                 category_input[0][0]             \n",
      "                                                                 shop_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 16)           3136        inputs_concat[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 4)            68          dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "final_out (Dense)               (None, 1)            5           dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,233\n",
      "Trainable params: 3,233\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1593032 samples, validate on 16092 samples\n",
      "Epoch 1/500\n",
      "1593032/1593032 [==============================] - 12s 7us/step - loss: 483.9760 - rmse: 483.9760 - val_loss: 634.0794 - val_rmse: 634.0794\n",
      "\n",
      "Epoch 00001: val_rmse improved from inf to 634.07940, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-01-634.079399.hdf5\n",
      "Epoch 2/500\n",
      "1593032/1593032 [==============================] - 13s 8us/step - loss: 377.1686 - rmse: 377.1686 - val_loss: 599.9675 - val_rmse: 599.9675\n",
      "\n",
      "Epoch 00002: val_rmse improved from 634.07940 to 599.96746, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-02-599.967455.hdf5\n",
      "Epoch 3/500\n",
      "1593032/1593032 [==============================] - 13s 8us/step - loss: 319.9932 - rmse: 319.9932 - val_loss: 528.5093 - val_rmse: 528.5093\n",
      "\n",
      "Epoch 00003: val_rmse improved from 599.96746 to 528.50928, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-03-528.509278.hdf5\n",
      "Epoch 4/500\n",
      "1593032/1593032 [==============================] - 12s 8us/step - loss: 292.2266 - rmse: 292.2266 - val_loss: 498.5959 - val_rmse: 498.5959\n",
      "\n",
      "Epoch 00004: val_rmse improved from 528.50928 to 498.59586, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-04-498.595862.hdf5\n",
      "Epoch 5/500\n",
      "1593032/1593032 [==============================] - 11s 7us/step - loss: 282.6585 - rmse: 282.6585 - val_loss: 488.7485 - val_rmse: 488.7485\n",
      "\n",
      "Epoch 00005: val_rmse improved from 498.59586 to 488.74849, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-05-488.748489.hdf5\n",
      "Epoch 6/500\n",
      "1593032/1593032 [==============================] - 11s 7us/step - loss: 275.8470 - rmse: 275.8470 - val_loss: 478.5955 - val_rmse: 478.5955\n",
      "\n",
      "Epoch 00006: val_rmse improved from 488.74849 to 478.59547, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-06-478.595470.hdf5\n",
      "Epoch 7/500\n",
      "1593032/1593032 [==============================] - 11s 7us/step - loss: 270.3674 - rmse: 270.3674 - val_loss: 474.2504 - val_rmse: 474.2504\n",
      "\n",
      "Epoch 00007: val_rmse improved from 478.59547 to 474.25042, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-07-474.250423.hdf5\n",
      "Epoch 8/500\n",
      "1593032/1593032 [==============================] - 11s 7us/step - loss: 266.0757 - rmse: 266.0757 - val_loss: 466.2159 - val_rmse: 466.2159\n",
      "\n",
      "Epoch 00008: val_rmse improved from 474.25042 to 466.21593, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-08-466.215926.hdf5\n",
      "Epoch 9/500\n",
      "1593032/1593032 [==============================] - 10s 6us/step - loss: 262.6959 - rmse: 262.6959 - val_loss: 460.6707 - val_rmse: 460.6707\n",
      "\n",
      "Epoch 00009: val_rmse improved from 466.21593 to 460.67073, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-09-460.670729.hdf5\n",
      "Epoch 10/500\n",
      "1593032/1593032 [==============================] - 10s 6us/step - loss: 260.1536 - rmse: 260.1536 - val_loss: 456.6400 - val_rmse: 456.6400\n",
      "\n",
      "Epoch 00010: val_rmse improved from 460.67073 to 456.63995, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-10-456.639950.hdf5\n",
      "Epoch 11/500\n",
      "1593032/1593032 [==============================] - 10s 7us/step - loss: 257.6827 - rmse: 257.6827 - val_loss: 453.7794 - val_rmse: 453.7794\n",
      "\n",
      "Epoch 00011: val_rmse improved from 456.63995 to 453.77941, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-11-453.779414.hdf5\n",
      "Epoch 12/500\n",
      "1593032/1593032 [==============================] - 10s 6us/step - loss: 256.1674 - rmse: 256.1674 - val_loss: 448.6865 - val_rmse: 448.6865\n",
      "\n",
      "Epoch 00012: val_rmse improved from 453.77941 to 448.68648, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-12-448.686480.hdf5\n",
      "Epoch 13/500\n",
      "1593032/1593032 [==============================] - 10s 6us/step - loss: 254.4811 - rmse: 254.4811 - val_loss: 445.5499 - val_rmse: 445.5499\n",
      "\n",
      "Epoch 00013: val_rmse improved from 448.68648 to 445.54993, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-13-445.549928.hdf5\n",
      "Epoch 14/500\n",
      "1593032/1593032 [==============================] - 10s 6us/step - loss: 253.3102 - rmse: 253.3102 - val_loss: 442.4593 - val_rmse: 442.4593\n",
      "\n",
      "Epoch 00014: val_rmse improved from 445.54993 to 442.45927, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-14-442.459272.hdf5\n",
      "Epoch 15/500\n",
      "1593032/1593032 [==============================] - 10s 6us/step - loss: 252.3065 - rmse: 252.3065 - val_loss: 437.5957 - val_rmse: 437.5957\n",
      "\n",
      "Epoch 00015: val_rmse improved from 442.45927 to 437.59566, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-15-437.595661.hdf5\n",
      "Epoch 16/500\n",
      "1593032/1593032 [==============================] - 10s 6us/step - loss: 251.3707 - rmse: 251.3707 - val_loss: 435.7515 - val_rmse: 435.7515\n",
      "\n",
      "Epoch 00016: val_rmse improved from 437.59566 to 435.75150, saving model to ./price_trained_model/lr0.01_12d13-25/weights-improvement-16-435.751503.hdf5\n",
      "Epoch 17/500\n",
      "1593032/1593032 [==============================] - ETA: 0s - loss: 250.6251 - rmse: 250.62 - 10s 6us/step - loss: 250.5883 - rmse: 250.5883 - val_loss: 437.7738 - val_rmse: 437.7738\n",
      "\n",
      "Epoch 00017: val_rmse did not improve from 435.75150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/500\n",
      "1593032/1593032 [==============================] - 12s 8us/step - loss: 249.9519 - rmse: 249.9519 - val_loss: 437.8149 - val_rmse: 437.8149\n",
      "\n",
      "Epoch 00018: val_rmse did not improve from 435.75150\n",
      "214200/214200 [==============================] - 8s 37us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\coding\\python\\lib\\site-packages\\ipykernel_launcher.py:86: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['item_price'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-440871f1b995>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shop_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'item_price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'price_table.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2678\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2679\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2680\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2721\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2722\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2723\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['item_price'] not in index\""
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Embedding, Input, Concatenate, Flatten, BatchNormalization, Activation, Dropout, Lambda\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,TerminateOnNaN\n",
    "from keras import optimizers, initializers\n",
    "from keras.backend import sqrt\n",
    "from keras.losses import mean_squared_error\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# create training inputs and target\n",
    "x = X[['date_block_num','month',\n",
    "       'item_vec','cat_vec','shop_vec', 'item_price']].values\n",
    "inputs = [x[:,i].tolist() for i in range(x.shape[1]-1)]\n",
    "y = x[:,-1]\n",
    "\n",
    "# training spec\n",
    "keras.backend.clear_session()\n",
    "NUM_EPOCHS = 500\n",
    "LEARNING_RATE= 0.01\n",
    "BETA1=0.9\n",
    "adam = optimizers.Adam(lr=LEARNING_RATE, beta_1=BETA1)\n",
    "\n",
    "def build_model():\n",
    "    #  features: 'date_block_num','month','price','item_vec','cat_vec','shop_vec'\n",
    "    #  input layers\n",
    "    date = Input(shape=(1,), name='date_input')\n",
    "    month = Input(shape=(1,), name='month_input', dtype='int32')\n",
    "    \n",
    "    item = Input(shape=(64,), name='item_input')\n",
    "    cat = Input(shape=(64,), name='category_input')\n",
    "    shop = Input(shape=(64,), name='shop_input')\n",
    "    \n",
    "    # embedding layers\n",
    "    month_emb = Embedding(input_dim=12, output_dim=2, input_length=1, name='month_emb')(month)\n",
    "    month_flat = Flatten(name='month_flat')(month_emb)\n",
    "    \n",
    "    # all inputs concatenation\n",
    "    inputs = Concatenate(axis=-1, name='inputs_concat')([date, month_flat,\n",
    "                                                         item, cat, shop])\n",
    "    \n",
    "    # dnn layers\n",
    "    preds = Dense(16, activation='relu', name='dense1')(inputs)\n",
    "    preds = Dense(4, activation='relu',name='dense2')(preds)\n",
    "\n",
    "    # output layer\n",
    "    preds = Dense(1, activation='relu', name='final_out')(preds)\n",
    "\n",
    "    return Model(inputs=[date, month, item, cat, shop], outputs=preds)\n",
    "    \n",
    "def rmse(y_true, y_pred):\n",
    "    return sqrt(mean_squared_error(y_true, y_pred)+0.00001)\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "model.compile(optimizer = adam,loss=rmse, metrics=[rmse])\n",
    "\n",
    "OUTPUT_DIR = './price_trained_model/'+ 'lr' + str(LEARNING_RATE) + '_' + datetime.now().strftime(\"%dd%H-%M\")\n",
    "filepath = OUTPUT_DIR +'/' + \"weights-improvement-{epoch:02d}-{val_rmse:.6f}.hdf5\"\n",
    "\n",
    "# model = load_model('keras/weights-improvement-02-14.970410.hdf5')\n",
    "# model.load_weights('trained_model/lr0.001_09d11-32/weights-improvement-22-0.827185.hdf5')\n",
    "\n",
    "callbacks = [\n",
    "             TerminateOnNaN(),\n",
    "             ModelCheckpoint(filepath=filepath, monitor='val_rmse', verbose=1, period=1, save_best_only=True),\n",
    "             EarlyStopping(patience=2, monitor='val_loss'),\n",
    "             TensorBoard(log_dir=OUTPUT_DIR, write_images=False, histogram_freq=1, write_grads=True),\n",
    "#              keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0),\n",
    "             keras.callbacks.CSVLogger('log.csv', separator=',', append=False)\n",
    "]\n",
    "\n",
    "model.fit(inputs, y, batch_size = 2048, epochs=NUM_EPOCHS, callbacks=callbacks, shuffle=True,\n",
    "          validation_split=0.01)\n",
    "\n",
    "\n",
    "X_test = pd.read_csv('data/test.csv', dtype={'shop_id': np.int32, 'item_id': np.int32})\n",
    "X_test['date_block_num'] = 34\n",
    "X_test['month'] = 11\n",
    "X_test = preprocessing(X_test)\n",
    "\n",
    "x_test = X_test[['date_block_num','month',\n",
    "       'item_vec','cat_vec','shop_vec']].values\n",
    "\n",
    "inputs_test = [x_test[:,i].tolist() for i in range(x_test.shape[1])]\n",
    "X_test['item_price'] = model.predict(inputs_test, verbose=1).flatten().tolist()\n",
    "\n",
    "X_test[['shop_id', 'item_id','item_price']].to_csv('price_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
