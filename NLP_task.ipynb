{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data/train.csv', dtype={'shop_id': np.int32, 'item_id': np.int32, 'item_cnt_day':np.int32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabularies\n",
    "shops = pd.read_csv('data/shops.csv')\n",
    "items = pd.read_csv('data/items.csv')\n",
    "item_cats = pd.read_csv('data/item_categories.csv')\n",
    "SHOPS_COUNT = len(shops)\n",
    "ITEMS_COUNT = len(items)\n",
    "CATS_COUNT = len(item_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polyglot\n",
    "from polyglot.detect import Detector\n",
    "import string\n",
    "\n",
    "VOCAB_SIZE = 64\n",
    "embeddings_ru = Embedding.load(\"data/ru_embeddings_pkl.tar.bz2\")\n",
    "embeddings_en = Embedding.load(\"data/en_embeddings_pkl.tar.bz2\")\n",
    "punctuation_table = str.maketrans({key: None for key in string.punctuation+string.digits})\n",
    "\n",
    "def encoder(entries):\n",
    "    encoded = []\n",
    "    for i,entry in enumerate(entries.tolist()):\n",
    "        entry = entry.translate(punctuation_table)\n",
    "\n",
    "        temp = []\n",
    "        for word in entry.split(\" \"):\n",
    "            if word.replace(\" \", \"\") in embeddings_en:\n",
    "                temp.append(embeddings_en[word])\n",
    "            elif word.replace(\" \", \"\") in embeddings_ru:\n",
    "                temp.append(embeddings_ru[word]) \n",
    "            else:\n",
    "                temp.append(np.array([0]*64)) \n",
    "        temp = np.array(temp).mean(axis=0)\n",
    "        encoded.append(temp)\n",
    "    return encoded\n",
    "\n",
    "shop_vec = encoder(shops.shop_name)\n",
    "item_vec = encoder(items.item_name)\n",
    "cat_vec = encoder(item_cats.item_category_name)\n",
    "\n",
    "shops['shop_vec'] = shop_vec\n",
    "items['item_vec'] = item_vec\n",
    "item_cats['cat_vec'] = cat_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dt):\n",
    "    # add feature month to train data\n",
    "    dt['month'] = dt.date_block_num % 12\n",
    "    dt['item_category_id'] = dt.join(items, on='item_id', how='left', lsuffix='item_id').item_category_id\n",
    "    dt['item_vec'] = dt.join(items, on='item_id', how='left', rsuffix='ref').item_vec\n",
    "    dt['cat_vec'] = dt.join(item_cats, on='item_category_id', how='left', rsuffix='ref').cat_vec\n",
    "    dt['shop_vec'] = dt.join(shops, on='shop_id', how='left', rsuffix='ref').shop_vec\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data.groupby(['date_block_num','shop_id', 'item_id', 'item_price'])['item_cnt_day'].sum()).reset_index()\n",
    "X = preprocessing(X)\n",
    "X = X[['date_block_num','month','item_vec','cat_vec','shop_vec','item_cnt_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('data/test.csv', dtype={'shop_id': np.int32, 'item_id': np.int32})\n",
    "X_test['date_block_num'] = 34\n",
    "X_test['month'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocessing(X_test)\n",
    "X_test = X_test[['date_block_num','month','item_vec','cat_vec','shop_vec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "month_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_emb (Embedding)           (None, 1, 1)         12          month_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "date_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_flat (Flatten)            (None, 1)            0           month_emb[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "category_input (InputLayer)     (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_input (InputLayer)         (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inputs_concat (Concatenate)     (None, 194)          0           date_input[0][0]                 \n",
      "                                                                 month_flat[0][0]                 \n",
      "                                                                 item_input[0][0]                 \n",
      "                                                                 category_input[0][0]             \n",
      "                                                                 shop_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inputs_batchnorm (BatchNormaliz (None, 194)          776         inputs_concat[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 48)           9360        inputs_batchnorm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 16)           784         dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense3 (Dense)                  (None, 16)           272         dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "final_out (Dense)               (None, 1)            17          dense3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 11,221\n",
      "Trainable params: 10,833\n",
      "Non-trainable params: 388\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1721631 samples, validate on 17391 samples\n",
      "Epoch 1/50\n",
      "1721631/1721631 [==============================] - 19s 11us/step - loss: 1.1102 - rmse: 1.1102 - val_loss: 0.9608 - val_rmse: 0.9608\n",
      "\n",
      "Epoch 00001: val_rmse improved from inf to 0.96084, saving model to ./trained_model/lr0.001_09d10-37/weights-improvement-01-0.960837.hdf5\n",
      "Epoch 2/50\n",
      "1721631/1721631 [==============================] - 17s 10us/step - loss: 1.8435 - rmse: 1.8435 - val_loss: 1.9539 - val_rmse: 1.9539\n",
      "\n",
      "Epoch 00002: val_rmse did not improve from 0.96084\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Nan in summary histogram for: inputs_batchnorm/moving_mean_0\n\t [[node inputs_batchnorm/moving_mean_0 (defined at d:\\coding\\python\\lib\\site-packages\\keras\\callbacks.py:796)  = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](inputs_batchnorm/moving_mean_0/tag, inputs_batchnorm/moving_mean/read/_309)]]\n\nCaused by op 'inputs_batchnorm/moving_mean_0', defined at:\n  File \"d:\\coding\\python\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"d:\\coding\\python\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"d:\\coding\\python\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"d:\\coding\\python\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"d:\\coding\\python\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"d:\\coding\\python\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"d:\\coding\\python\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"d:\\coding\\python\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"d:\\coding\\python\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"d:\\coding\\python\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"d:\\coding\\python\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"d:\\coding\\python\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"d:\\coding\\python\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"d:\\coding\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"d:\\coding\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"d:\\coding\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"d:\\coding\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-420-58c6f1197f7b>\", line 76, in <module>\n    validation_split=0.01)\n  File \"d:\\coding\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1039, in fit\n    validation_steps=validation_steps)\n  File \"d:\\coding\\python\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 117, in fit_loop\n    callbacks.set_model(callback_model)\n  File \"d:\\coding\\python\\lib\\site-packages\\keras\\callbacks.py\", line 54, in set_model\n    callback.set_model(model)\n  File \"d:\\coding\\python\\lib\\site-packages\\keras\\callbacks.py\", line 796, in set_model\n    tf.summary.histogram(mapped_weight_name, weight)\n  File \"d:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\summary\\summary.py\", line 187, in histogram\n    tag=tag, values=values, name=scope)\n  File \"d:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\ops\\gen_logging_ops.py\", line 311, in histogram_summary\n    \"HistogramSummary\", tag=tag, values=values, name=name)\n  File \"d:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"d:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"d:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"d:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: inputs_batchnorm/moving_mean_0\n\t [[node inputs_batchnorm/moving_mean_0 (defined at d:\\coding\\python\\lib\\site-packages\\keras\\callbacks.py:796)  = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](inputs_batchnorm/moving_mean_0/tag, inputs_batchnorm/moving_mean/read/_309)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: inputs_batchnorm/moving_mean_0\n\t [[{{node inputs_batchnorm/moving_mean_0}} = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](inputs_batchnorm/moving_mean_0/tag, inputs_batchnorm/moving_mean/read/_309)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-420-58c6f1197f7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m model.fit(inputs, y, batch_size = 1024, epochs=NUM_EPOCHS, callbacks=callbacks, shuffle=True,\n\u001b[1;32m---> 76\u001b[1;33m           validation_split=0.01)\n\u001b[0m",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    215\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    939\u001b[0m                     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_val\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m                     \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m                     \u001b[0msummary_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: inputs_batchnorm/moving_mean_0\n\t [[node inputs_batchnorm/moving_mean_0 (defined at d:\\coding\\python\\lib\\site-packages\\keras\\callbacks.py:796)  = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](inputs_batchnorm/moving_mean_0/tag, inputs_batchnorm/moving_mean/read/_309)]]\n\nCaused by op 'inputs_batchnorm/moving_mean_0', defined at:\n  File \"d:\\coding\\python\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"d:\\coding\\python\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"d:\\coding\\python\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"d:\\coding\\python\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"d:\\coding\\python\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"d:\\coding\\python\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"d:\\coding\\python\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"d:\\coding\\python\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"d:\\coding\\python\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"d:\\coding\\python\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"d:\\coding\\python\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"d:\\coding\\python\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"d:\\coding\\python\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"d:\\coding\\python\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"d:\\coding\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"d:\\coding\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"d:\\coding\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"d:\\coding\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-420-58c6f1197f7b>\", line 76, in <module>\n    validation_split=0.01)\n  File \"d:\\coding\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1039, in fit\n    validation_steps=validation_steps)\n  File \"d:\\coding\\python\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 117, in fit_loop\n    callbacks.set_model(callback_model)\n  File \"d:\\coding\\python\\lib\\site-packages\\keras\\callbacks.py\", line 54, in set_model\n    callback.set_model(model)\n  File \"d:\\coding\\python\\lib\\site-packages\\keras\\callbacks.py\", line 796, in set_model\n    tf.summary.histogram(mapped_weight_name, weight)\n  File \"d:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\summary\\summary.py\", line 187, in histogram\n    tag=tag, values=values, name=scope)\n  File \"d:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\ops\\gen_logging_ops.py\", line 311, in histogram_summary\n    \"HistogramSummary\", tag=tag, values=values, name=name)\n  File \"d:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"d:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"d:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"d:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: inputs_batchnorm/moving_mean_0\n\t [[node inputs_batchnorm/moving_mean_0 (defined at d:\\coding\\python\\lib\\site-packages\\keras\\callbacks.py:796)  = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](inputs_batchnorm/moving_mean_0/tag, inputs_batchnorm/moving_mean/read/_309)]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Embedding, Input, Concatenate, Flatten, BatchNormalization, Activation, Dropout, Lambda\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,TerminateOnNaN\n",
    "from keras import optimizers, initializers\n",
    "from keras.backend import sqrt\n",
    "from keras.losses import mean_squared_error\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# create training inputs and target\n",
    "x = X.values\n",
    "inputs = [x[:,i].tolist() for i in range(x.shape[1]-1)]\n",
    "y = x[:,-1]\n",
    "\n",
    "# training spec\n",
    "keras.backend.clear_session()\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE= 0.001\n",
    "BETA1=0.90\n",
    "\n",
    "def build_model():\n",
    "#     features: 'date_block_num','month','item_vec','cat_vec','shop_vec'\n",
    "#   input layers--numeric \n",
    "    date = Input(shape=(1,), name='date_input')\n",
    "    month = Input(shape=(1,), name='month_input', dtype='int32')\n",
    "    \n",
    "    item = Input(shape=(64,), name='item_input')\n",
    "    cat = Input(shape=(64,), name='category_input')\n",
    "    shop = Input(shape=(64,), name='shop_input')\n",
    "\n",
    "    month_emb = Embedding(input_dim=12, output_dim=1, input_length=1, name='month_emb')(month)\n",
    "    month_flat = Flatten(name='month_flat')(month_emb)\n",
    "    \n",
    "    inputs = Concatenate(axis=-1, name='inputs_concat')([date, month_flat, item, cat, shop])\n",
    "    inputs_batch = BatchNormalization(name='inputs_batchnorm')(inputs)\n",
    "    \n",
    "    preds = Dense(48, activation='relu', name='dense1')(inputs_batch)\n",
    "#     preds = Dropout(0.1)(preds)\n",
    "    preds = Dense(16, activation='relu',name='dense2')(preds)\n",
    "#     preds = Dropout(0.1)(preds)\n",
    "    preds = Dense(16, activation='relu', name='dense3')(preds)\n",
    "\n",
    "    # preds = Dense(8,activation ='relu', name='out_nn')(all_inputs)\n",
    "    preds = Dense(1, activation='relu', name='final_out')(preds)\n",
    "\n",
    "    return Model(inputs=[date, month, item,cat, shop], outputs=preds)\n",
    "    \n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "adam = optimizers.Adam(lr=LEARNING_RATE, beta_1=BETA1)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return sqrt(mean_squared_error(y_true, y_pred))\n",
    "   \n",
    "model.compile(optimizer = adam,loss=rmse, metrics=[rmse])\n",
    "\n",
    "OUTPUT_DIR = './trained_model/'+ 'lr' + str(LEARNING_RATE) + '_' + datetime.now().strftime(\"%dd%H-%M\")\n",
    "filepath = OUTPUT_DIR +'/' + \"weights-improvement-{epoch:02d}-{val_rmse:.6f}.hdf5\"\n",
    "\n",
    "# model = load_model('keras/weights-improvement-02-14.970410.hdf5')\n",
    "# model.load_weights('trained_model/lr0.0001_04d16-09/weights-improvement-08-1.191472.hdf5')\n",
    "\n",
    "callbacks = [\n",
    "             TerminateOnNaN(),\n",
    "             ModelCheckpoint(filepath=filepath, monitor='val_rmse', verbose=1, period=1, save_best_only=True),\n",
    "             # EarlyStopping(patience=2, monitor='loss'),\n",
    "             TensorBoard(log_dir=OUTPUT_DIR, write_images=False, histogram_freq=1, write_grads=True),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0),\n",
    "             keras.callbacks.CSVLogger('log.csv', separator=',', append=False)\n",
    "]\n",
    "\n",
    "model.fit(inputs, y, batch_size = 1024, epochs=NUM_EPOCHS, callbacks=callbacks, shuffle=True,\n",
    "          validation_split=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214200/214200 [==============================] - 11s 50us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# vocabularies\n",
    "# X_test = pd.read_csv('X_test.csv')\n",
    "\n",
    "x_test = X_test.values\n",
    "inputs_test = [x_test[:,i].tolist() for i in range(x_test.shape[1])]\n",
    "\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "model = load_model('trained_model/lr1e-05_09d10-23/weights-improvement-01-1.352098.hdf5', {'rmse':rmse, 'sqrt':sqrt})\n",
    "\n",
    "y_out = model.predict(inputs_test, verbose=1).flatten().tolist()\n",
    "y_out = [20 if i>20 else i for i in y_out]\n",
    "\n",
    "import csv\n",
    "with open('predictions.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(('ID','item_cnt_month'))\n",
    "    for i in range(len(y_out)):\n",
    "        writer.writerow((i, y_out[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214200"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
