{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv', dtype={'shop_id': np.int32, 'item_id': np.int32, 'item_cnt_day':np.int32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabularies\n",
    "shops = pd.read_csv('data/shops.csv')\n",
    "items = pd.read_csv('data/items.csv')\n",
    "item_cats = pd.read_csv('data/item_categories.csv')\n",
    "SHOPS_COUNT = len(shops)\n",
    "ITEMS_COUNT = len(items)\n",
    "CATS_COUNT = len(item_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polyglot\n",
    "from polyglot.detect import Detector\n",
    "from polyglot.mapping import Embedding\n",
    "import string\n",
    "\n",
    "VOCAB_SIZE = 64\n",
    "embeddings_ru = Embedding.load(\"data/ru_embeddings_pkl.tar.bz2\")\n",
    "embeddings_en = Embedding.load(\"data/en_embeddings_pkl.tar.bz2\")\n",
    "punctuation_table = str.maketrans({key: None for key in string.punctuation+string.digits})\n",
    "\n",
    "def encoder(entries):\n",
    "    encoded = []\n",
    "    for i,entry in enumerate(entries.tolist()):\n",
    "        entry = entry.translate(punctuation_table)\n",
    "\n",
    "        temp = []\n",
    "        for word in entry.split(\" \"):\n",
    "            if word.replace(\" \", \"\") in embeddings_en:\n",
    "                temp.append(embeddings_en[word])\n",
    "            elif word.replace(\" \", \"\") in embeddings_ru:\n",
    "                temp.append(embeddings_ru[word]) \n",
    "            else:\n",
    "                temp.append(np.array([0]*64)) \n",
    "        temp = np.array(temp).mean(axis=0)\n",
    "        encoded.append(temp)\n",
    "    return encoded\n",
    "\n",
    "shop_vec = encoder(shops.shop_name)\n",
    "item_vec = encoder(items.item_name)\n",
    "cat_vec = encoder(item_cats.item_category_name)\n",
    "\n",
    "shops['shop_vec'] = shop_vec\n",
    "items['item_vec'] = item_vec\n",
    "item_cats['cat_vec'] = cat_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dt):\n",
    "    # add feature month to train data\n",
    "    dt['month'] = dt.date_block_num % 12\n",
    "    dt['item_category_id'] = dt.join(items, on='item_id', how='left', lsuffix='item_id').item_category_id\n",
    "    dt['item_vec'] = dt.join(items, on='item_id', how='left', rsuffix='ref').item_vec\n",
    "    dt['cat_vec'] = dt.join(item_cats, on='item_category_id', how='left', rsuffix='ref').cat_vec\n",
    "    dt['shop_vec'] = dt.join(shops, on='shop_id', how='left', rsuffix='ref').shop_vec\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data.groupby(['date_block_num','shop_id', 'item_id'])['item_cnt_day'].sum()).reset_index()\n",
    "X['item_price'] = pd.DataFrame(\n",
    "    data.groupby(['date_block_num','shop_id', 'item_id'])['item_price'].mean()).reset_index().item_price\n",
    "X = preprocessing(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "month_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id_input (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cat_id_input (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_id_input (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_emb (Embedding)           (None, 1, 2)         24          month_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "item_emb (Embedding)            (None, 1, 16)        354720      item_id_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cat_emb (Embedding)             (None, 1, 4)         336         cat_id_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "shop_emb (Embedding)            (None, 1, 4)         240         shop_id_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "date_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_flat (Flatten)            (None, 2)            0           month_emb[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "price_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_flat (Flatten)             (None, 16)           0           item_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cat_flat (Flatten)              (None, 4)            0           cat_emb[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "shop_flat (Flatten)             (None, 4)            0           shop_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "category_input (InputLayer)     (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_input (InputLayer)         (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inputs_concat (Concatenate)     (None, 220)          0           date_input[0][0]                 \n",
      "                                                                 month_flat[0][0]                 \n",
      "                                                                 price_input[0][0]                \n",
      "                                                                 item_flat[0][0]                  \n",
      "                                                                 cat_flat[0][0]                   \n",
      "                                                                 shop_flat[0][0]                  \n",
      "                                                                 item_input[0][0]                 \n",
      "                                                                 category_input[0][0]             \n",
      "                                                                 shop_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inputs_batchnorm (BatchNormaliz (None, 220)          880         inputs_concat[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 64)           14144       inputs_batchnorm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32)           2080        dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm1 (BatchNormalization) (None, 32)           128         dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense3 (Dense)                  (None, 16)           528         batchnorm1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "final_out (Dense)               (None, 1)            17          dense3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 373,097\n",
      "Trainable params: 372,593\n",
      "Non-trainable params: 504\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1593032 samples, validate on 16092 samples\n",
      "Epoch 1/500\n",
      "1593032/1593032 [==============================] - 17s 11us/step - loss: 1.2230 - rmse: 1.2230 - val_loss: 0.9127 - val_rmse: 0.9127\n",
      "\n",
      "Epoch 00001: val_rmse improved from inf to 0.91271, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-01-0.912707.hdf5\n",
      "Epoch 2/500\n",
      "1593032/1593032 [==============================] - 15s 9us/step - loss: 1.0640 - rmse: 1.0640 - val_loss: 0.8836 - val_rmse: 0.8836\n",
      "\n",
      "Epoch 00002: val_rmse improved from 0.91271 to 0.88364, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-02-0.883639.hdf5\n",
      "Epoch 3/500\n",
      "1593032/1593032 [==============================] - 15s 9us/step - loss: 1.0261 - rmse: 1.0261 - val_loss: 0.8716 - val_rmse: 0.8716\n",
      "\n",
      "Epoch 00003: val_rmse improved from 0.88364 to 0.87156, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-03-0.871560.hdf5\n",
      "Epoch 4/500\n",
      "1593032/1593032 [==============================] - 15s 9us/step - loss: 0.9911 - rmse: 0.9911 - val_loss: 0.8630 - val_rmse: 0.8630\n",
      "\n",
      "Epoch 00004: val_rmse improved from 0.87156 to 0.86304, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-04-0.863044.hdf5\n",
      "Epoch 5/500\n",
      "1593032/1593032 [==============================] - 15s 9us/step - loss: 0.9651 - rmse: 0.9651 - val_loss: 0.8703 - val_rmse: 0.8703\n",
      "\n",
      "Epoch 00005: val_rmse did not improve from 0.86304\n",
      "Epoch 6/500\n",
      "1593032/1593032 [==============================] - 14s 8us/step - loss: 0.9371 - rmse: 0.9371 - val_loss: 0.8440 - val_rmse: 0.8440\n",
      "\n",
      "Epoch 00006: val_rmse improved from 0.86304 to 0.84398, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-06-0.843980.hdf5\n",
      "Epoch 7/500\n",
      "1593032/1593032 [==============================] - 14s 9us/step - loss: 0.9153 - rmse: 0.9153 - val_loss: 0.8564 - val_rmse: 0.8564\n",
      "\n",
      "Epoch 00007: val_rmse did not improve from 0.84398\n",
      "Epoch 8/500\n",
      "1593032/1593032 [==============================] - 14s 9us/step - loss: 0.9009 - rmse: 0.9009 - val_loss: 0.8152 - val_rmse: 0.8152\n",
      "\n",
      "Epoch 00008: val_rmse improved from 0.84398 to 0.81523, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-08-0.815233.hdf5\n",
      "Epoch 9/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1593032/1593032 [==============================] - 19s 12us/step - loss: 0.8863 - rmse: 0.8863 - val_loss: 0.8483 - val_rmse: 0.8483\n",
      "\n",
      "Epoch 00009: val_rmse did not improve from 0.81523\n",
      "Epoch 10/500\n",
      "1593032/1593032 [==============================] - 20s 12us/step - loss: 0.8744 - rmse: 0.8744 - val_loss: 0.7971 - val_rmse: 0.7971\n",
      "\n",
      "Epoch 00010: val_rmse improved from 0.81523 to 0.79707, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-10-0.797068.hdf5\n",
      "Epoch 11/500\n",
      "1593032/1593032 [==============================] - 19s 12us/step - loss: 0.8642 - rmse: 0.8642 - val_loss: 0.7932 - val_rmse: 0.7932\n",
      "\n",
      "Epoch 00011: val_rmse improved from 0.79707 to 0.79321, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-11-0.793214.hdf5\n",
      "Epoch 12/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.8566 - rmse: 0.8566 - val_loss: 0.7809 - val_rmse: 0.7809\n",
      "\n",
      "Epoch 00012: val_rmse improved from 0.79321 to 0.78092, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-12-0.780919.hdf5\n",
      "Epoch 13/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.8494 - rmse: 0.8494 - val_loss: 0.7982 - val_rmse: 0.7982\n",
      "\n",
      "Epoch 00013: val_rmse did not improve from 0.78092\n",
      "Epoch 14/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.8433 - rmse: 0.8433 - val_loss: 0.7754 - val_rmse: 0.7754\n",
      "\n",
      "Epoch 00014: val_rmse improved from 0.78092 to 0.77538, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-14-0.775377.hdf5\n",
      "Epoch 15/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.8343 - rmse: 0.8343 - val_loss: 0.7825 - val_rmse: 0.7825\n",
      "\n",
      "Epoch 00015: val_rmse did not improve from 0.77538\n",
      "Epoch 16/500\n",
      "1593032/1593032 [==============================] - 18s 12us/step - loss: 0.8287 - rmse: 0.8287 - val_loss: 0.7758 - val_rmse: 0.7758\n",
      "\n",
      "Epoch 00016: val_rmse did not improve from 0.77538\n",
      "Epoch 17/500\n",
      "1593032/1593032 [==============================] - 15s 9us/step - loss: 0.8216 - rmse: 0.8216 - val_loss: 0.7537 - val_rmse: 0.7537\n",
      "\n",
      "Epoch 00017: val_rmse improved from 0.77538 to 0.75372, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-17-0.753718.hdf5\n",
      "Epoch 18/500\n",
      "1593032/1593032 [==============================] - 15s 9us/step - loss: 0.8147 - rmse: 0.8147 - val_loss: 0.7726 - val_rmse: 0.7726\n",
      "\n",
      "Epoch 00018: val_rmse did not improve from 0.75372\n",
      "Epoch 19/500\n",
      "1593032/1593032 [==============================] - 15s 9us/step - loss: 0.8102 - rmse: 0.8102 - val_loss: 0.7688 - val_rmse: 0.7688\n",
      "\n",
      "Epoch 00019: val_rmse did not improve from 0.75372\n",
      "Epoch 20/500\n",
      "1593032/1593032 [==============================] - 14s 9us/step - loss: 0.8036 - rmse: 0.8036 - val_loss: 0.7453 - val_rmse: 0.7453\n",
      "\n",
      "Epoch 00020: val_rmse improved from 0.75372 to 0.74528, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-20-0.745278.hdf5\n",
      "Epoch 21/500\n",
      "1593032/1593032 [==============================] - 15s 9us/step - loss: 0.7989 - rmse: 0.7989 - val_loss: 0.7503 - val_rmse: 0.7503\n",
      "\n",
      "Epoch 00021: val_rmse did not improve from 0.74528\n",
      "Epoch 22/500\n",
      "1593032/1593032 [==============================] - 14s 9us/step - loss: 0.7937 - rmse: 0.7937 - val_loss: 0.7580 - val_rmse: 0.7580\n",
      "\n",
      "Epoch 00022: val_rmse did not improve from 0.74528\n",
      "Epoch 23/500\n",
      "1593032/1593032 [==============================] - 14s 9us/step - loss: 0.7897 - rmse: 0.7897 - val_loss: 0.7696 - val_rmse: 0.7696\n",
      "\n",
      "Epoch 00023: val_rmse did not improve from 0.74528\n",
      "Epoch 24/500\n",
      "1593032/1593032 [==============================] - 14s 9us/step - loss: 0.7865 - rmse: 0.7865 - val_loss: 0.7493 - val_rmse: 0.7493\n",
      "\n",
      "Epoch 00024: val_rmse did not improve from 0.74528\n",
      "Epoch 25/500\n",
      "1593032/1593032 [==============================] - 13s 8us/step - loss: 0.7864 - rmse: 0.7864 - val_loss: 0.7544 - val_rmse: 0.7544\n",
      "\n",
      "Epoch 00025: val_rmse did not improve from 0.74528\n",
      "Epoch 26/500\n",
      "1593032/1593032 [==============================] - 14s 9us/step - loss: 0.7799 - rmse: 0.7799 - val_loss: 0.7520 - val_rmse: 0.7520\n",
      "\n",
      "Epoch 00026: val_rmse did not improve from 0.74528\n",
      "Epoch 27/500\n",
      "1593032/1593032 [==============================] - 14s 9us/step - loss: 0.7768 - rmse: 0.7768 - val_loss: 0.7483 - val_rmse: 0.7483\n",
      "\n",
      "Epoch 00027: val_rmse did not improve from 0.74528\n",
      "Epoch 28/500\n",
      "1593032/1593032 [==============================] - 13s 8us/step - loss: 0.7722 - rmse: 0.7722 - val_loss: 0.7526 - val_rmse: 0.7526\n",
      "\n",
      "Epoch 00028: val_rmse did not improve from 0.74528\n",
      "Epoch 29/500\n",
      "1593032/1593032 [==============================] - 14s 9us/step - loss: 0.7696 - rmse: 0.7696 - val_loss: 0.7423 - val_rmse: 0.7423\n",
      "\n",
      "Epoch 00029: val_rmse improved from 0.74528 to 0.74234, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-29-0.742339.hdf5\n",
      "Epoch 30/500\n",
      "1593032/1593032 [==============================] - 14s 9us/step - loss: 0.7682 - rmse: 0.7682 - val_loss: 0.7227 - val_rmse: 0.7227\n",
      "\n",
      "Epoch 00030: val_rmse improved from 0.74234 to 0.72267, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-30-0.722675.hdf5\n",
      "Epoch 31/500\n",
      "1593032/1593032 [==============================] - 12s 8us/step - loss: 0.7642 - rmse: 0.7642 - val_loss: 0.7378 - val_rmse: 0.7378\n",
      "\n",
      "Epoch 00031: val_rmse did not improve from 0.72267\n",
      "Epoch 32/500\n",
      "1593032/1593032 [==============================] - 16s 10us/step - loss: 0.7604 - rmse: 0.7604 - val_loss: 0.7299 - val_rmse: 0.7299\n",
      "\n",
      "Epoch 00032: val_rmse did not improve from 0.72267\n",
      "Epoch 33/500\n",
      "1593032/1593032 [==============================] - 16s 10us/step - loss: 0.7574 - rmse: 0.7574 - val_loss: 0.7231 - val_rmse: 0.7231\n",
      "\n",
      "Epoch 00033: val_rmse did not improve from 0.72267\n",
      "Epoch 34/500\n",
      "1593032/1593032 [==============================] - 16s 10us/step - loss: 0.7562 - rmse: 0.7562 - val_loss: 0.7320 - val_rmse: 0.7320\n",
      "\n",
      "Epoch 00034: val_rmse did not improve from 0.72267\n",
      "Epoch 35/500\n",
      "1593032/1593032 [==============================] - 16s 10us/step - loss: 0.7517 - rmse: 0.7517 - val_loss: 0.7302 - val_rmse: 0.7302\n",
      "\n",
      "Epoch 00035: val_rmse did not improve from 0.72267\n",
      "Epoch 36/500\n",
      "1593032/1593032 [==============================] - 16s 10us/step - loss: 0.7487 - rmse: 0.7487 - val_loss: 0.7337 - val_rmse: 0.7337\n",
      "\n",
      "Epoch 00036: val_rmse did not improve from 0.72267\n",
      "Epoch 37/500\n",
      "1593032/1593032 [==============================] - 16s 10us/step - loss: 0.7456 - rmse: 0.7456 - val_loss: 0.7153 - val_rmse: 0.7153\n",
      "\n",
      "Epoch 00037: val_rmse improved from 0.72267 to 0.71527, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-37-0.715270.hdf5\n",
      "Epoch 38/500\n",
      "1593032/1593032 [==============================] - 16s 10us/step - loss: 0.7448 - rmse: 0.7448 - val_loss: 0.7166 - val_rmse: 0.7166\n",
      "\n",
      "Epoch 00038: val_rmse did not improve from 0.71527\n",
      "Epoch 39/500\n",
      "1593032/1593032 [==============================] - 16s 10us/step - loss: 0.7424 - rmse: 0.7424 - val_loss: 0.7231 - val_rmse: 0.7231\n",
      "\n",
      "Epoch 00039: val_rmse did not improve from 0.71527\n",
      "Epoch 40/500\n",
      "1593032/1593032 [==============================] - 16s 10us/step - loss: 0.7397 - rmse: 0.7397 - val_loss: 0.7146 - val_rmse: 0.7146\n",
      "\n",
      "Epoch 00040: val_rmse improved from 0.71527 to 0.71456, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-40-0.714564.hdf5\n",
      "Epoch 41/500\n",
      "1593032/1593032 [==============================] - 16s 10us/step - loss: 0.7384 - rmse: 0.7384 - val_loss: 0.7308 - val_rmse: 0.7308\n",
      "\n",
      "Epoch 00041: val_rmse did not improve from 0.71456\n",
      "Epoch 42/500\n",
      "1593032/1593032 [==============================] - 16s 10us/step - loss: 0.7364 - rmse: 0.7364 - val_loss: 0.7232 - val_rmse: 0.7232\n",
      "\n",
      "Epoch 00042: val_rmse did not improve from 0.71456\n",
      "Epoch 43/500\n",
      "1593032/1593032 [==============================] - 16s 10us/step - loss: 0.7338 - rmse: 0.7338 - val_loss: 0.7060 - val_rmse: 0.7060\n",
      "\n",
      "Epoch 00043: val_rmse improved from 0.71456 to 0.70598, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-43-0.705980.hdf5\n",
      "Epoch 44/500\n",
      "1593032/1593032 [==============================] - 16s 10us/step - loss: 0.7311 - rmse: 0.7311 - val_loss: 0.7194 - val_rmse: 0.7194\n",
      "\n",
      "Epoch 00044: val_rmse did not improve from 0.70598\n",
      "Epoch 45/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1593032/1593032 [==============================] - 20s 12us/step - loss: 0.7307 - rmse: 0.7307 - val_loss: 0.7546 - val_rmse: 0.7546\n",
      "\n",
      "Epoch 00045: val_rmse did not improve from 0.70598\n",
      "Epoch 46/500\n",
      "1593032/1593032 [==============================] - 20s 12us/step - loss: 0.7269 - rmse: 0.7269 - val_loss: 0.7196 - val_rmse: 0.7196\n",
      "\n",
      "Epoch 00046: val_rmse did not improve from 0.70598\n",
      "Epoch 47/500\n",
      "1593032/1593032 [==============================] - 19s 12us/step - loss: 0.7279 - rmse: 0.7279 - val_loss: 0.7125 - val_rmse: 0.7125\n",
      "\n",
      "Epoch 00047: val_rmse did not improve from 0.70598\n",
      "Epoch 48/500\n",
      "1593032/1593032 [==============================] - 19s 12us/step - loss: 0.7235 - rmse: 0.7235 - val_loss: 0.7123 - val_rmse: 0.7123\n",
      "\n",
      "Epoch 00048: val_rmse did not improve from 0.70598\n",
      "Epoch 49/500\n",
      "1593032/1593032 [==============================] - 19s 12us/step - loss: 0.7231 - rmse: 0.7231 - val_loss: 0.7236 - val_rmse: 0.7236\n",
      "\n",
      "Epoch 00049: val_rmse did not improve from 0.70598\n",
      "Epoch 50/500\n",
      "1593032/1593032 [==============================] - 19s 12us/step - loss: 0.7219 - rmse: 0.7219 - val_loss: 0.7318 - val_rmse: 0.7318\n",
      "\n",
      "Epoch 00050: val_rmse did not improve from 0.70598\n",
      "Epoch 51/500\n",
      "1593032/1593032 [==============================] - 19s 12us/step - loss: 0.7187 - rmse: 0.7187 - val_loss: 0.7380 - val_rmse: 0.7380\n",
      "\n",
      "Epoch 00051: val_rmse did not improve from 0.70598\n",
      "Epoch 52/500\n",
      "1593032/1593032 [==============================] - 19s 12us/step - loss: 0.7199 - rmse: 0.7199 - val_loss: 0.7155 - val_rmse: 0.7155\n",
      "\n",
      "Epoch 00052: val_rmse did not improve from 0.70598\n",
      "Epoch 53/500\n",
      "1593032/1593032 [==============================] - 19s 12us/step - loss: 0.7149 - rmse: 0.7149 - val_loss: 0.7310 - val_rmse: 0.7310\n",
      "\n",
      "Epoch 00053: val_rmse did not improve from 0.70598\n",
      "Epoch 54/500\n",
      "1593032/1593032 [==============================] - 19s 12us/step - loss: 0.7158 - rmse: 0.7158 - val_loss: 0.7162 - val_rmse: 0.7162\n",
      "\n",
      "Epoch 00054: val_rmse did not improve from 0.70598\n",
      "Epoch 55/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.7128 - rmse: 0.7128 - val_loss: 0.7221 - val_rmse: 0.7221\n",
      "\n",
      "Epoch 00055: val_rmse did not improve from 0.70598\n",
      "Epoch 56/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.7126 - rmse: 0.7126 - val_loss: 0.7261 - val_rmse: 0.7261\n",
      "\n",
      "Epoch 00056: val_rmse did not improve from 0.70598\n",
      "Epoch 57/500\n",
      "1593032/1593032 [==============================] - 19s 12us/step - loss: 0.7124 - rmse: 0.7124 - val_loss: 0.7143 - val_rmse: 0.7143\n",
      "\n",
      "Epoch 00057: val_rmse did not improve from 0.70598\n",
      "Epoch 58/500\n",
      "1593032/1593032 [==============================] - 19s 12us/step - loss: 0.7100 - rmse: 0.7100 - val_loss: 0.7007 - val_rmse: 0.7007\n",
      "\n",
      "Epoch 00058: val_rmse improved from 0.70598 to 0.70065, saving model to ./trained_model/lr0.001_12d13-39/weights-improvement-58-0.700651.hdf5\n",
      "Epoch 59/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.7081 - rmse: 0.7081 - val_loss: 0.7147 - val_rmse: 0.7147\n",
      "\n",
      "Epoch 00059: val_rmse did not improve from 0.70065\n",
      "Epoch 60/500\n",
      "1593032/1593032 [==============================] - 18s 12us/step - loss: 0.7079 - rmse: 0.7079 - val_loss: 0.7120 - val_rmse: 0.7120\n",
      "\n",
      "Epoch 00060: val_rmse did not improve from 0.70065\n",
      "Epoch 61/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.7074 - rmse: 0.7074 - val_loss: 0.7171 - val_rmse: 0.7171\n",
      "\n",
      "Epoch 00061: val_rmse did not improve from 0.70065\n",
      "Epoch 62/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.7071 - rmse: 0.7071 - val_loss: 0.7307 - val_rmse: 0.7307\n",
      "\n",
      "Epoch 00062: val_rmse did not improve from 0.70065\n",
      "Epoch 63/500\n",
      "1593032/1593032 [==============================] - 18s 12us/step - loss: 0.7047 - rmse: 0.7047 - val_loss: 0.7118 - val_rmse: 0.7118\n",
      "\n",
      "Epoch 00063: val_rmse did not improve from 0.70065\n",
      "Epoch 64/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.7040 - rmse: 0.7040 - val_loss: 0.7211 - val_rmse: 0.7211\n",
      "\n",
      "Epoch 00064: val_rmse did not improve from 0.70065\n",
      "Epoch 65/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.7021 - rmse: 0.7021 - val_loss: 0.7144 - val_rmse: 0.7144\n",
      "\n",
      "Epoch 00065: val_rmse did not improve from 0.70065\n",
      "Epoch 66/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.7011 - rmse: 0.7011 - val_loss: 0.7155 - val_rmse: 0.7155\n",
      "\n",
      "Epoch 00066: val_rmse did not improve from 0.70065\n",
      "Epoch 67/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.7020 - rmse: 0.7020 - val_loss: 0.7062 - val_rmse: 0.7062\n",
      "\n",
      "Epoch 00067: val_rmse did not improve from 0.70065\n",
      "Epoch 68/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.6983 - rmse: 0.6983 - val_loss: 0.7266 - val_rmse: 0.7266\n",
      "\n",
      "Epoch 00068: val_rmse did not improve from 0.70065\n",
      "Epoch 69/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.7006 - rmse: 0.7006 - val_loss: 0.7166 - val_rmse: 0.7166\n",
      "\n",
      "Epoch 00069: val_rmse did not improve from 0.70065\n",
      "Epoch 70/500\n",
      "1593032/1593032 [==============================] - 18s 11us/step - loss: 0.6994 - rmse: 0.6994 - val_loss: 0.7079 - val_rmse: 0.7079\n",
      "\n",
      "Epoch 00070: val_rmse did not improve from 0.70065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fcc5555390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Embedding, Input, Concatenate, Flatten, BatchNormalization, Activation, Dropout, Lambda\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,TerminateOnNaN\n",
    "from keras import optimizers, initializers\n",
    "from keras.backend import sqrt\n",
    "from keras.losses import mean_squared_error\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# create training inputs and target\n",
    "x = X[['date_block_num','month','item_price',\n",
    "       'item_id', 'item_category_id', 'shop_id',\n",
    "       'item_vec','cat_vec','shop_vec','item_cnt_day']].values\n",
    "inputs = [x[:,i].tolist() for i in range(x.shape[1]-1)]\n",
    "y = x[:,-1]\n",
    "\n",
    "# training spec\n",
    "keras.backend.clear_session()\n",
    "NUM_EPOCHS = 500\n",
    "LEARNING_RATE= 0.001\n",
    "BETA1=0.9\n",
    "adam = optimizers.Adam(lr=LEARNING_RATE, beta_1=BETA1)\n",
    "\n",
    "def build_model():\n",
    "    #  features: 'date_block_num','month','price','item_vec','cat_vec','shop_vec'\n",
    "    #  input layers\n",
    "    date = Input(shape=(1,), name='date_input')\n",
    "    month = Input(shape=(1,), name='month_input', dtype='int32')\n",
    "    price =  Input(shape=(1,), name='price_input')\n",
    "    \n",
    "    item_id = Input(shape=(1,), name='item_id_input', dtype='int32')\n",
    "    cat_id = Input(shape=(1,), name='cat_id_input', dtype='int32')\n",
    "    shop_id = Input(shape=(1,), name='shop_id_input', dtype='int32')\n",
    "    \n",
    "    item = Input(shape=(64,), name='item_input')\n",
    "    cat = Input(shape=(64,), name='category_input')\n",
    "    shop = Input(shape=(64,), name='shop_input')\n",
    "    \n",
    "    # embedding layers\n",
    "    month_emb = Embedding(input_dim=12, output_dim=2, input_length=1, name='month_emb')(month)\n",
    "    month_flat = Flatten(name='month_flat')(month_emb)\n",
    "    \n",
    "    item_emb = Embedding(input_dim=ITEMS_COUNT, output_dim=16, input_length=1, name='item_emb')(item_id)\n",
    "    item_flat = Flatten(name='item_flat')(item_emb)\n",
    "    \n",
    "    cat_emb = Embedding(input_dim=CATS_COUNT, output_dim=4, input_length=1, name='cat_emb')(cat_id)\n",
    "    cat_flat = Flatten(name='cat_flat')(cat_emb)\n",
    "    \n",
    "    shop_emb = Embedding(input_dim=SHOPS_COUNT, output_dim=4, input_length=1, name='shop_emb')(shop_id)\n",
    "    shop_flat = Flatten(name='shop_flat')(shop_emb)\n",
    "    \n",
    "    \n",
    "    # all inputs concatenation\n",
    "    inputs = Concatenate(axis=-1, name='inputs_concat')([date, month_flat, price, \n",
    "                                                         item_flat, cat_flat, shop_flat, \n",
    "                                                         item, cat, shop])\n",
    "    inputs_batch = BatchNormalization(name='inputs_batchnorm')(inputs)\n",
    "    \n",
    "    # dnn layers\n",
    "    preds = Dense(64, activation='relu', name='dense1')(inputs_batch)\n",
    "    preds = Dense(32, activation='relu',name='dense2')(preds)\n",
    "    preds = BatchNormalization(name='batchnorm1')(preds)\n",
    "    preds = Dense(16, activation='relu', name='dense3')(preds)\n",
    "\n",
    "    # output layer\n",
    "    preds = Dense(1, activation='relu', name='final_out')(preds)\n",
    "\n",
    "    return Model(inputs=[date, month, price, \n",
    "                         item_id, cat_id, shop_id, \n",
    "                         item, cat, shop], outputs=preds)\n",
    "    \n",
    "def rmse(y_true, y_pred):\n",
    "    return sqrt(mean_squared_error(y_true, y_pred)+0.00001)\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "model.compile(optimizer = adam,loss=rmse, metrics=[rmse])\n",
    "\n",
    "OUTPUT_DIR = './trained_model/'+ 'lr' + str(LEARNING_RATE) + '_' + datetime.now().strftime(\"%dd%H-%M\")\n",
    "filepath = OUTPUT_DIR +'/' + \"weights-improvement-{epoch:02d}-{val_rmse:.6f}.hdf5\"\n",
    "\n",
    "# model = load_model('keras/weights-improvement-02-14.970410.hdf5')\n",
    "# model.load_weights('trained_model/lr0.001_09d11-32/weights-improvement-22-0.827185.hdf5')\n",
    "\n",
    "callbacks = [\n",
    "             TerminateOnNaN(),\n",
    "             ModelCheckpoint(filepath=filepath, monitor='val_rmse', verbose=1, period=1, save_best_only=True),\n",
    "             EarlyStopping(patience=2, monitor='loss'),\n",
    "             TensorBoard(log_dir=OUTPUT_DIR, write_images=False, histogram_freq=1, write_grads=True),\n",
    "#              keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0),\n",
    "             keras.callbacks.CSVLogger('log.csv', separator=',', append=False)\n",
    "]\n",
    "\n",
    "model.fit(inputs, y, batch_size = 2048, epochs=NUM_EPOCHS, callbacks=callbacks, shuffle=True,\n",
    "          validation_split=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('data/test.csv', dtype={'shop_id': np.int32, 'item_id': np.int32})\n",
    "X_test['date_block_num'] = 34\n",
    "X_test['month'] = 11\n",
    "X_test = preprocessing(X_test)\n",
    "\n",
    "# find the nearest month\n",
    "ref_month = pd.merge(X_test,X,\n",
    "                     how='left',\n",
    "                     on=['shop_id', 'item_id'], \n",
    "                     suffixes=['_test','_train']).groupby(['shop_id', 'item_id'])['date_block_num_train'].max().reset_index().rename(columns={'date_block_num_train':'date_block_num'})\n",
    "\n",
    "# query price of nearest month\n",
    "refs = pd.merge(ref_month, X,\n",
    "                how='left',\n",
    "                on=['shop_id', 'item_id', 'date_block_num'],)[['shop_id', 'item_id', 'item_price']]\n",
    "\n",
    "# fill NAs using predictions from price_table\n",
    "missing = refs.loc[refs.item_price.isnull(), ['shop_id','item_id']]\n",
    "price_table = pd.read_csv('price_table.csv')\n",
    "missing_price = pd.merge(missing, price_table, on=('shop_id','item_id')).item_price\n",
    "refs.loc[refs.item_price.isnull(), 'item_price'] = missing_price\n",
    "                         \n",
    "X_test['item_price'] = pd.merge(X_test, refs, how='left', on=['shop_id', 'item_id']).item_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214200/214200 [==============================] - 16s 77us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "x_test = X_test[['date_block_num','month','item_price',\n",
    "       'item_id', 'item_category_id', 'shop_id',\n",
    "       'item_vec','cat_vec','shop_vec']].values\n",
    "inputs_test = [x_test[:,i].tolist() for i in range(x_test.shape[1])]\n",
    "\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# model = load_model('trained_model/\\lr0.001_11d17-21\\weights-improvement-11-0.860732.hdf5', {'rmse':rmse, 'sqrt':sqrt})\n",
    "\n",
    "y_out = model.predict(inputs_test, verbose=1).flatten().tolist()\n",
    "y_out = [20 if i>20 else i for i in y_out]\n",
    "\n",
    "import csv\n",
    "with open('predictions.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(('ID','item_cnt_month'))\n",
    "    for i in range(len(y_out)):\n",
    "        writer.writerow((i, y_out[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
